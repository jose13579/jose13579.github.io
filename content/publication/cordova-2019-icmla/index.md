---
# Documentation: https://wowchemy.com/docs/managing-content/

title: 'Pelee-Text: A Tiny Convolutional Neural Network for Multi-oriented Scene Text Detection'
subtitle: ''
summary: ''
authors:
- M. A. Córdova
- L. G. L. Decker
- J. L. Flores-Campana
- A. A. dos Santos
- J. S. Conceição
- A. Pinto
- H. Pedrini
- R. da S. Torres
tags:
- '"Text Localization"'
- '"Text Recognition"'
- '"Machine Learning"'
- '"Computer Vision"'
- '"Mobile Devices"'
categories: []
date: '2019-12-01'
lastmod: 2021-08-14T23:55:30-03:00
featured: false
draft: false

# Custom links (uncomment lines below)
links:
 - name: Link
   url: https://ieeexplore.ieee.org/document/8999065

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-08-15T02:55:30.043643Z'
publication_types:
- '1'
abstract: Nowadays, scene text detection has received a lot of attention due to its
  complexity given variations in terms of orientations, font size, aspect ratio, and
  natural backgrounds. In this vein, several deep neural networks have been proposed
  to deal with this challenging problem. However, such networks produce \"heavy\"
  models, hampering their use in applications running in devices with computational
  constraints. Additionally, few works are focused on the detection of multi-oriented
  and/or multi-lingual text. Herein, we propose an end-to-end tiny convolutional neural
  network for multi-oriented multi-lingual scene text called Pelee- Text. Experimental
  results show that Pelee-Text is at least 3 times smaller than its counterparts with
  a speed of 2.93 and 18.64 frames per second for its multi-scale and 768-scale versions,
  respectively. Moreover, in terms of F-measure, our method achieved competitive results
  on four well-known datasets, i.e., ICDAR'2011 (90.96%), ICDAR'2013 (85.24%), ICDAR'2015
  (80.08%), and MSRA-TD500 (80.90%).
publication: '*2019 18th IEEE International Conference On Machine Learning And Applications
  ( ICMLA)*'
url_pdf: uploads/2019-Cordova2019ICMLA.pdf
doi: 10.1109/ICMLA.2019.00075
---
